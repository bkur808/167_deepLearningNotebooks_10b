{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/udlbook/udlbook/blob/main/Notebooks/Chap10/10_2_Convolution_for_MNIST_1D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9vk9Elugvmi"
      },
      "source": [
        "# **Notebook 10.2: Convolution for MNIST-1D**\n",
        "\n",
        "This notebook investigates a 1D convolutional network for MNIST-1D as in figure 10.7 and 10.8a.\n",
        "\n",
        "Work through the cells below, running each cell in turn. In various places you will see the words \"TO DO\". Follow the instructions at these places and make predictions about what is going to happen or write code to complete the functions.\n",
        "\n",
        "Contact me at udlbookmail@gmail.com if you find any mistakes or have any suggestions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5yLObtZCi9J"
      },
      "outputs": [],
      "source": [
        "# Run this if you're in a Colab to install MNIST 1D repository\n",
        "!pip install git+https://github.com/greydanus/mnist1d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YrXWAH7sUWvU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "import mnist1d\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "twI72ZCrCt5z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded data from ./mnist1d_data.pkl\n",
            "Examples in training set: 4000\n",
            "Examples in test set: 1000\n",
            "Length of each example: 40\n"
          ]
        }
      ],
      "source": [
        "args = mnist1d.data.get_dataset_args()\n",
        "data = mnist1d.data.get_dataset(args, path='./mnist1d_data.pkl', download=False, regenerate=False)\n",
        "\n",
        "# The training and test input and outputs are in\n",
        "# data['x'], data['y'], data['x_test'], and data['y_test']\n",
        "print(\"Examples in training set: {}\".format(len(data['y'])))\n",
        "print(\"Examples in test set: {}\".format(len(data['y_test'])))\n",
        "print(\"Length of each example: {}\".format(data['x'].shape[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8bKADvLHbiV5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data: 4000 examples (columns), each of which has 40 dimensions (rows)\n",
            "Validation data: 1000 examples (columns), each of which has 40 dimensions (rows)\n"
          ]
        }
      ],
      "source": [
        "# Load in the data\n",
        "train_data_x = data['x'].transpose()\n",
        "train_data_y = data['y']\n",
        "val_data_x = data['x_test'].transpose()\n",
        "val_data_y = data['y_test']\n",
        "# Print out sizes\n",
        "print(\"Train data: %d examples (columns), each of which has %d dimensions (rows)\"%((train_data_x.shape[1],train_data_x.shape[0])))\n",
        "print(\"Validation data: %d examples (columns), each of which has %d dimensions (rows)\"%((val_data_x.shape[1],val_data_x.shape[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sFvRDGrl4qe"
      },
      "source": [
        "Define the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FslroPJJffrh"
      },
      "outputs": [],
      "source": [
        "# There are 40 input dimensions and 10 output dimensions for this data\n",
        "# The inputs correspond to the 40 offsets in the MNIST1D template.\n",
        "D_i = 40\n",
        "# The outputs correspond to the 10 digits\n",
        "D_o = 10\n",
        "\n",
        "\n",
        "# TODO Create a model with the following layers\n",
        "# 1. Convolutional layer, (input=length 40 and 1 channel, kernel size 3, stride 2, padding=\"valid\", 15 output channels )\n",
        "# 2. ReLU\n",
        "# 3. Convolutional layer, (input=length 19 and 15 channels, kernel size 3, stride 2, padding=\"valid\", 15 output channels )\n",
        "# 4. ReLU\n",
        "# 5. Convolutional layer, (input=length 9 and 15 channels, kernel size 3, stride 2, padding=\"valid\", 15 output channels)\n",
        "# 6. ReLU\n",
        "# 7. Flatten (converts 4x15) to length 60\n",
        "# 8. Linear layer (input size = 60, output size = 10)\n",
        "# References:\n",
        "# https://pytorch.org/docs/1.13/generated/torch.nn.Conv1d.html?highlight=conv1d#torch.nn.Conv1d\n",
        "# https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html\n",
        "# https://pytorch.org/docs/1.13/generated/torch.nn.Linear.html?highlight=linear#torch.nn.Linear\n",
        "\n",
        "# NOTE THAT THE CONVOLUTIONAL LAYERS NEED TO TAKE THE NUMBER OF INPUT CHANNELS AS A PARAMETER\n",
        "# AND NOT THE INPUT SIZE.\n",
        "\n",
        "# Replace the following function:\n",
        "model = nn.Sequential(\n",
        "nn.Conv1d(in_channels = 1, out_channels = 15, kernel_size = 3, stride = 2, padding = \"valid\"),\n",
        "nn.ReLU(),\n",
        "nn.Conv1d(in_channels = 15, out_channels = 15, kernel_size = 3, stride = 2, padding = \"valid\"),\n",
        "nn.ReLU(),\n",
        "nn.Conv1d(in_channels = 15, out_channels = 15, kernel_size = 3, stride = 2, padding = \"valid\"),\n",
        "nn.ReLU(),\n",
        "nn.Flatten(),\n",
        "nn.Linear(60,10))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YgLaex1pfhqz"
      },
      "outputs": [],
      "source": [
        "# He initialization of weights\n",
        "def weights_init(layer_in):\n",
        "  if isinstance(layer_in, nn.Linear):\n",
        "    nn.init.kaiming_uniform_(layer_in.weight)\n",
        "    layer_in.bias.data.fill_(0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NYw8I_3mmX5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch     0, train loss 2.131381, train error 82.70,  val loss 2.127339, percent error 84.20\n",
            "Epoch     1, train loss 1.523897, train error 59.58,  val loss 1.546739, percent error 64.70\n",
            "Epoch     2, train loss 1.384123, train error 55.03,  val loss 1.390731, percent error 57.80\n",
            "Epoch     3, train loss 1.267868, train error 51.60,  val loss 1.300902, percent error 53.40\n",
            "Epoch     4, train loss 1.239554, train error 51.28,  val loss 1.234904, percent error 53.70\n",
            "Epoch     5, train loss 1.138799, train error 46.70,  val loss 1.149267, percent error 49.80\n",
            "Epoch     6, train loss 1.231246, train error 49.97,  val loss 1.241315, percent error 51.60\n",
            "Epoch     7, train loss 0.966563, train error 38.72,  val loss 1.008978, percent error 41.30\n",
            "Epoch     8, train loss 0.819088, train error 31.93,  val loss 0.870310, percent error 35.20\n",
            "Epoch     9, train loss 0.772687, train error 29.03,  val loss 0.838783, percent error 31.70\n",
            "Epoch    10, train loss 0.677501, train error 25.70,  val loss 0.750389, percent error 28.40\n",
            "Epoch    11, train loss 0.651366, train error 24.65,  val loss 0.730094, percent error 27.40\n",
            "Epoch    12, train loss 0.530922, train error 20.97,  val loss 0.643324, percent error 24.80\n",
            "Epoch    13, train loss 0.508348, train error 19.20,  val loss 0.631115, percent error 22.60\n",
            "Epoch    14, train loss 0.416578, train error 15.88,  val loss 0.521678, percent error 19.20\n",
            "Epoch    15, train loss 0.373525, train error 13.80,  val loss 0.501189, percent error 18.70\n",
            "Epoch    16, train loss 0.387203, train error 14.18,  val loss 0.521578, percent error 16.60\n",
            "Epoch    17, train loss 0.349278, train error 12.95,  val loss 0.493385, percent error 15.70\n",
            "Epoch    18, train loss 0.336827, train error 12.93,  val loss 0.477010, percent error 16.40\n",
            "Epoch    19, train loss 0.323056, train error 12.22,  val loss 0.462947, percent error 16.60\n",
            "Epoch    20, train loss 0.238345, train error 8.35,  val loss 0.410547, percent error 13.60\n",
            "Epoch    21, train loss 0.203260, train error 6.75,  val loss 0.394333, percent error 12.50\n",
            "Epoch    22, train loss 0.183480, train error 5.57,  val loss 0.386001, percent error 13.10\n",
            "Epoch    23, train loss 0.165501, train error 5.18,  val loss 0.381471, percent error 12.40\n",
            "Epoch    24, train loss 0.169894, train error 5.43,  val loss 0.395105, percent error 11.10\n",
            "Epoch    25, train loss 0.146501, train error 4.40,  val loss 0.377251, percent error 10.70\n",
            "Epoch    26, train loss 0.163625, train error 5.78,  val loss 0.413560, percent error 13.10\n",
            "Epoch    27, train loss 0.153112, train error 5.30,  val loss 0.402982, percent error 14.20\n",
            "Epoch    28, train loss 0.134929, train error 4.45,  val loss 0.389456, percent error 10.80\n",
            "Epoch    29, train loss 0.141224, train error 5.05,  val loss 0.418951, percent error 11.60\n",
            "Epoch    30, train loss 0.143005, train error 5.00,  val loss 0.444613, percent error 12.90\n",
            "Epoch    31, train loss 0.109568, train error 3.22,  val loss 0.380009, percent error 10.50\n",
            "Epoch    32, train loss 0.110315, train error 3.68,  val loss 0.400993, percent error 10.90\n",
            "Epoch    33, train loss 0.092896, train error 2.55,  val loss 0.388041, percent error 10.40\n",
            "Epoch    34, train loss 0.112272, train error 3.45,  val loss 0.444541, percent error 11.30\n",
            "Epoch    35, train loss 0.088152, train error 2.60,  val loss 0.398273, percent error 10.80\n",
            "Epoch    36, train loss 0.086732, train error 2.88,  val loss 0.394603, percent error 10.00\n",
            "Epoch    37, train loss 0.098062, train error 3.72,  val loss 0.433879, percent error 10.10\n",
            "Epoch    38, train loss 0.079194, train error 2.53,  val loss 0.394940, percent error 10.30\n",
            "Epoch    39, train loss 0.072111, train error 2.15,  val loss 0.409461, percent error 10.50\n",
            "Epoch    40, train loss 0.057143, train error 1.50,  val loss 0.391650, percent error 9.30\n",
            "Epoch    41, train loss 0.053947, train error 0.95,  val loss 0.395138, percent error 9.10\n",
            "Epoch    42, train loss 0.053938, train error 1.28,  val loss 0.411091, percent error 9.50\n",
            "Epoch    43, train loss 0.053301, train error 1.25,  val loss 0.402328, percent error 9.40\n",
            "Epoch    44, train loss 0.053857, train error 1.32,  val loss 0.421004, percent error 10.20\n",
            "Epoch    45, train loss 0.052107, train error 1.30,  val loss 0.426880, percent error 9.80\n",
            "Epoch    46, train loss 0.046989, train error 0.88,  val loss 0.419787, percent error 9.50\n",
            "Epoch    47, train loss 0.068496, train error 2.25,  val loss 0.464910, percent error 10.90\n",
            "Epoch    48, train loss 0.048657, train error 0.97,  val loss 0.436792, percent error 10.00\n",
            "Epoch    49, train loss 0.051330, train error 1.05,  val loss 0.422520, percent error 10.10\n",
            "Epoch    50, train loss 0.046007, train error 1.28,  val loss 0.447390, percent error 8.90\n",
            "Epoch    51, train loss 0.049001, train error 1.43,  val loss 0.441012, percent error 9.60\n",
            "Epoch    52, train loss 0.043658, train error 0.82,  val loss 0.467252, percent error 10.40\n",
            "Epoch    53, train loss 0.039318, train error 0.70,  val loss 0.436151, percent error 9.50\n",
            "Epoch    54, train loss 0.037819, train error 0.75,  val loss 0.441375, percent error 9.80\n",
            "Epoch    55, train loss 0.049204, train error 1.38,  val loss 0.441858, percent error 9.90\n",
            "Epoch    56, train loss 0.037669, train error 0.62,  val loss 0.447457, percent error 9.90\n",
            "Epoch    57, train loss 0.037807, train error 0.82,  val loss 0.466785, percent error 10.20\n",
            "Epoch    58, train loss 0.036426, train error 0.72,  val loss 0.453995, percent error 10.10\n",
            "Epoch    59, train loss 0.038619, train error 0.85,  val loss 0.458578, percent error 10.40\n",
            "Epoch    60, train loss 0.031741, train error 0.62,  val loss 0.454995, percent error 10.40\n",
            "Epoch    61, train loss 0.033015, train error 0.57,  val loss 0.457823, percent error 9.70\n",
            "Epoch    62, train loss 0.032657, train error 0.50,  val loss 0.472895, percent error 10.40\n",
            "Epoch    63, train loss 0.031191, train error 0.50,  val loss 0.463745, percent error 10.00\n",
            "Epoch    64, train loss 0.030920, train error 0.53,  val loss 0.469193, percent error 10.30\n",
            "Epoch    65, train loss 0.029046, train error 0.47,  val loss 0.466386, percent error 10.20\n",
            "Epoch    66, train loss 0.029368, train error 0.50,  val loss 0.467921, percent error 9.80\n",
            "Epoch    67, train loss 0.031361, train error 0.53,  val loss 0.475986, percent error 10.00\n",
            "Epoch    68, train loss 0.028516, train error 0.43,  val loss 0.467307, percent error 9.90\n",
            "Epoch    69, train loss 0.027495, train error 0.43,  val loss 0.467950, percent error 9.80\n",
            "Epoch    70, train loss 0.029567, train error 0.40,  val loss 0.477826, percent error 10.00\n",
            "Epoch    71, train loss 0.027638, train error 0.38,  val loss 0.479658, percent error 9.80\n",
            "Epoch    72, train loss 0.028879, train error 0.47,  val loss 0.479296, percent error 10.50\n",
            "Epoch    73, train loss 0.027282, train error 0.40,  val loss 0.484656, percent error 10.40\n",
            "Epoch    74, train loss 0.026097, train error 0.35,  val loss 0.471218, percent error 9.70\n",
            "Epoch    75, train loss 0.026090, train error 0.38,  val loss 0.475360, percent error 9.80\n",
            "Epoch    76, train loss 0.025883, train error 0.30,  val loss 0.484323, percent error 9.80\n",
            "Epoch    77, train loss 0.025219, train error 0.30,  val loss 0.476944, percent error 9.40\n",
            "Epoch    78, train loss 0.025639, train error 0.32,  val loss 0.474862, percent error 9.70\n",
            "Epoch    79, train loss 0.024795, train error 0.30,  val loss 0.484206, percent error 10.00\n",
            "Epoch    80, train loss 0.024194, train error 0.25,  val loss 0.487605, percent error 10.30\n",
            "Epoch    81, train loss 0.023950, train error 0.22,  val loss 0.488596, percent error 9.90\n",
            "Epoch    82, train loss 0.023910, train error 0.25,  val loss 0.488638, percent error 10.00\n",
            "Epoch    83, train loss 0.023502, train error 0.22,  val loss 0.487267, percent error 9.80\n",
            "Epoch    84, train loss 0.023433, train error 0.22,  val loss 0.488073, percent error 9.90\n",
            "Epoch    85, train loss 0.023279, train error 0.22,  val loss 0.490221, percent error 10.10\n",
            "Epoch    86, train loss 0.023144, train error 0.20,  val loss 0.490159, percent error 9.90\n",
            "Epoch    87, train loss 0.023290, train error 0.22,  val loss 0.495301, percent error 10.00\n",
            "Epoch    88, train loss 0.023341, train error 0.22,  val loss 0.498578, percent error 10.30\n",
            "Epoch    89, train loss 0.022831, train error 0.20,  val loss 0.495251, percent error 10.20\n",
            "Epoch    90, train loss 0.022680, train error 0.20,  val loss 0.490848, percent error 9.70\n",
            "Epoch    91, train loss 0.022688, train error 0.15,  val loss 0.498640, percent error 10.00\n",
            "Epoch    92, train loss 0.022525, train error 0.22,  val loss 0.495027, percent error 9.80\n",
            "Epoch    93, train loss 0.022145, train error 0.18,  val loss 0.495780, percent error 9.90\n",
            "Epoch    94, train loss 0.022788, train error 0.20,  val loss 0.490160, percent error 9.40\n",
            "Epoch    95, train loss 0.021964, train error 0.15,  val loss 0.496702, percent error 9.90\n",
            "Epoch    96, train loss 0.021916, train error 0.18,  val loss 0.496862, percent error 9.80\n",
            "Epoch    97, train loss 0.021636, train error 0.12,  val loss 0.498022, percent error 9.70\n",
            "Epoch    98, train loss 0.021593, train error 0.15,  val loss 0.496241, percent error 9.80\n",
            "Epoch    99, train loss 0.021550, train error 0.18,  val loss 0.503471, percent error 10.20\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# choose cross entropy loss function (equation 5.24 in the loss notes)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "# construct SGD optimizer and initialize learning rate and momentum\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.05, momentum=0.9)\n",
        "# object that decreases learning rate by half every 20 epochs\n",
        "scheduler = StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "# create 100 dummy data points and store in data loader class\n",
        "x_train = torch.tensor(train_data_x.transpose().astype('float32'))\n",
        "y_train = torch.tensor(train_data_y.astype('long')).long()\n",
        "x_val= torch.tensor(val_data_x.transpose().astype('float32'))\n",
        "y_val = torch.tensor(val_data_y.astype('long')).long()\n",
        "\n",
        "# load the data into a class that creates the batches\n",
        "data_loader = DataLoader(TensorDataset(x_train,y_train), batch_size=100, shuffle=True, worker_init_fn=np.random.seed(1))\n",
        "\n",
        "# Initialize model weights\n",
        "model.apply(weights_init)\n",
        "\n",
        "# loop over the dataset n_epoch times\n",
        "n_epoch = 100\n",
        "# store the loss and the % correct at each epoch\n",
        "losses_train = np.zeros((n_epoch))\n",
        "errors_train = np.zeros((n_epoch))\n",
        "losses_val = np.zeros((n_epoch))\n",
        "errors_val = np.zeros((n_epoch))\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "  # loop over batches\n",
        "  for i, data in enumerate(data_loader):\n",
        "    # retrieve inputs and labels for this batch\n",
        "    x_batch, y_batch = data\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    # forward pass -- calculate model output\n",
        "    pred = model(x_batch[:,None,:])\n",
        "    # compute the loss\n",
        "    loss = loss_function(pred, y_batch)\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    # SGD update\n",
        "    optimizer.step()\n",
        "\n",
        "  # Run whole dataset to get statistics -- normally wouldn't do this\n",
        "  pred_train = model(x_train[:,None,:])\n",
        "  pred_val = model(x_val[:,None,:])\n",
        "  _, predicted_train_class = torch.max(pred_train.data, 1)\n",
        "  _, predicted_val_class = torch.max(pred_val.data, 1)\n",
        "  errors_train[epoch] = 100 - 100 * (predicted_train_class == y_train).float().sum() / len(y_train)\n",
        "  errors_val[epoch]= 100 - 100 * (predicted_val_class == y_val).float().sum() / len(y_val)\n",
        "  losses_train[epoch] = loss_function(pred_train, y_train).item()\n",
        "  losses_val[epoch]= loss_function(pred_val, y_val).item()\n",
        "  print(f'Epoch {epoch:5d}, train loss {losses_train[epoch]:.6f}, train error {errors_train[epoch]:3.2f},  val loss {losses_val[epoch]:.6f}, percent error {errors_val[epoch]:3.2f}')\n",
        "\n",
        "  # tell scheduler to consider updating learning rate\n",
        "  scheduler.step()\n",
        "\n",
        "# Plot the results\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(errors_train,'r-',label='train')\n",
        "ax.plot(errors_val,'b-',label='validation')\n",
        "ax.set_ylim(0,100); ax.set_xlim(0,n_epoch)\n",
        "ax.set_xlabel('Epoch'); ax.set_ylabel('Error')\n",
        "ax.set_title('Part I: Validation Result %3.2f'%(errors_val[-1]))\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNb46PJB/CC1pcHGfjpUUZg",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
